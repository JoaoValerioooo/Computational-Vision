{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk0eYw8ojrFq"
      },
      "source": [
        "# Laboratory #3_2 : Image Classification using Bag of Visual Words\n",
        "\n",
        "At the end of this laboratory, you would get familiarized with\n",
        "\n",
        "*   Creating Bag of Visual Words\n",
        "    *   Feature Extraction\n",
        "    *   Codebook construction\n",
        "    *   Classification\n",
        "\n",
        "**Remember this is a graded exercise.**\n",
        "\n",
        "*   For every plot, make sure you provide appropriate titles, axis labels, legends, wherever applicable.\n",
        "*   Create reusable functions where ever possible, so that the code could be reused at different places.\n",
        "*   Mount your drive to access the images.\n",
        "*   Add sufficient comments and explanations wherever necessary.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYHw1lSBldl-",
        "outputId": "c1affcc7-28f9-4e0f-82dd-2bddf5e86d9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "aD5-E8PuaQ5P"
      },
      "outputs": [],
      "source": [
        "# Loading necessary libraries (Feel free to add new libraries if you need for any computation)\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from skimage.feature import ORB\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.io import imread\n",
        "from scipy.cluster.vq import vq\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ampx9DIJiuGN"
      },
      "source": [
        "## Loading dataset\n",
        "\n",
        "We will use 3 categories from Caltech 101 objects dataset for this experiment. Upload the dataset to the drive and mount it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PRSJP1XbG6-a"
      },
      "outputs": [],
      "source": [
        "# Path from your drive\n",
        "dataset_path = r'/content/drive/MyDrive/Caltech_101_subset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fNoe7u755X6Q"
      },
      "outputs": [],
      "source": [
        "categories = ['butterfly', 'kangaroo', 'dalmatian']\n",
        "ncl = len(categories) * 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxY0mDoK5EQj"
      },
      "source": [
        "*   Create a list of file and the corresponding labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQptvDX5AFem",
        "outputId": "d8526589-d1ca-4763-929f-96e500e8b260"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "data = []\n",
        "for categorie in ['butterfly', 'kangaroo', 'dalmatian']:\n",
        "  data += [[rgb2gray(imread(im)), categorie] for im in glob.glob(dataset_path + '/' + categorie + '/*.jpg')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3x42veHz5LDt",
        "outputId": "0b28b9a4-c13e-48e3-a75e-3deeb02a5546"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of images: 244\n"
          ]
        }
      ],
      "source": [
        "print('Total number of images:', len(data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgVhdjYz5Zhs"
      },
      "source": [
        "*   Create a train / test split where the test is 10% of the total data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "QzYnjzXBZXXt"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "# Split the data into classes\n",
        "butterfly_data = []\n",
        "kangaroo_data = []\n",
        "dalmatian_data = []\n",
        "for im in data:\n",
        "  if (im[1] == 'butterfly'): butterfly_data.append(im)\n",
        "  elif (im[1] == 'kangaroo'): kangaroo_data.append(im)\n",
        "  elif (im[1] == 'dalmatian'): dalmatian_data.append(im)\n",
        "\n",
        "# Shufffle the data to increase randomness\n",
        "random.shuffle(butterfly_data)\n",
        "random.shuffle(kangaroo_data)\n",
        "random.shuffle(dalmatian_data)\n",
        "\n",
        "# Split the data into train and test\n",
        "def data_splitter(data_sample):\n",
        "  limit = round(len(data_sample)*0.9)\n",
        "  x_train, x_test = data_sample[:limit], data_sample[limit:]\n",
        "  return x_train, x_test\n",
        "\n",
        "x_train = []\n",
        "x_test = []\n",
        "for data_sample in (butterfly_data, kangaroo_data, dalmatian_data):\n",
        "  x_train_prov, x_test_prov = data_splitter(data_sample)\n",
        "  x_train = x_train + x_train_prov\n",
        "  x_test = x_test + x_test_prov"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd057lAc5jze",
        "outputId": "9c52d9f6-94ad-4440-c8a3-d6ca59b0a0b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: 219\n",
            "Test set: 25\n"
          ]
        }
      ],
      "source": [
        "print('Train set:', len(x_train))\n",
        "print('Test set:', len(x_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Hl36Ej_5k6Y"
      },
      "source": [
        "*   How do you select the train/test split?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aOe27Kx5vtd"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*   In order to select the train/test split, it is essential to consider the split size, the class representation and the randomness.\n",
        "\n",
        "    1. **Split size:** these values are pre-defined in the assignment (train - 90% and test - 10%);\n",
        "\n",
        "    2. **Classes representation:** It is secured that all the classes are represented in the training and testing set. So, in each category of data (butterfly, kangaroo and dalmatian), it is selected 90% to the training data and 10% to the test data.\n",
        "\n",
        "    3. **Randomness:** To include randomness in the data, the function shuffle is used.\n",
        "    Note that in different executions the accuracy results might vary depending on the shuffle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18OZf2kfkVNB"
      },
      "source": [
        "## Feature Extraction using ORB\n",
        "\n",
        "The first step is to extract descriptors for each image in our dataset. We will use ORB to extract descriptors.\n",
        "\n",
        "*   Create ORB detector with 64 keypoints.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ptLbPcoow-ar"
      },
      "outputs": [],
      "source": [
        "# Creating the ORB detector\n",
        "ORB_detector = ORB(n_keypoints=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yinPkL8brow"
      },
      "source": [
        "*   Extract ORB descriptors from all the images in the train set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "PCiXJeLFxGtP"
      },
      "outputs": [],
      "source": [
        "# Get the descriptors\n",
        "def get_descriptors(x, detector):\n",
        "  # List of descriptors\n",
        "  x_descriptors = []\n",
        "  # Extract ORB descriptors\n",
        "  for im in x:\n",
        "    detector.detect_and_extract(im[0])\n",
        "    x_descriptors.append(detector.descriptors)\n",
        "  return x_descriptors\n",
        "\n",
        "# Get the descriptors from the train set\n",
        "x_train_descriptors = get_descriptors(x_train, ORB_detector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJehFdyt583b"
      },
      "source": [
        "*   What is the size of the feature descriptors? What does each dimension represent in the feature descriptors?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzTspvF96LeC",
        "outputId": "d860352a-f644-4c8f-950b-3da386a3d232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total size of the feature descriptors: 219\n"
          ]
        }
      ],
      "source": [
        "# Size\n",
        "print('Total size of the feature descriptors:', len(x_train_descriptors))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNFOjsRj6PGk"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*   In ORB, the descriptors are obtained based on the key points defined previously. Firstly, the key points are utilised to identify key regions of the image. Usually, a suitable key point is one that is invariant to varying lighting conditions, angle, scale, and background.\n",
        "\n",
        "    Based on that, descriptors are created in order to describe these key points. So, it is obtained as many features per image as the key points defined. Relatively to the dimensions, mainly, each descriptor uses the intensity centroid as a measure of the orientation. For the \"descriptors\" variable, the rows represent the number of key points and the columns are the descriptor size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "420YQkAzleTQ"
      },
      "source": [
        "## Codebook Construction\n",
        "\n",
        "Codewords are nothing but vector representation of similar patches. This codeword produces a codebook similar to a word dictionary. We will create the codebook using K-Means algorithm\n",
        "\n",
        "*   Create a codebook using K-Means with k=number_of_classes*10\n",
        "*   Hint: Use sklearn.cluster.MiniBatchKMeans for K-Means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "iO0e4718ppJt"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import MiniBatchKMeans\n",
        "\n",
        "# Reshape the descriptors of each image\n",
        "def reshaper(x_descriptors):\n",
        "  x_descriptors_reshape = []\n",
        "  for im in x_descriptors:\n",
        "    feat = []\n",
        "    for desc in im:\n",
        "      feat.extend(desc)\n",
        "    x_descriptors_reshape.append(feat)\n",
        "  return x_descriptors_reshape\n",
        "\n",
        "# Get the reshaped descriptors\n",
        "x_train_descriptors_reshape = reshaper(x_train_descriptors)\n",
        "# Cluster the descriptors\n",
        "kmeans = MiniBatchKMeans(n_clusters=ncl, random_state=1).fit(x_train_descriptors_reshape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GAD_JuNpqMt"
      },
      "source": [
        "*   Create a histogram using the cluster centers for each image descriptor.\n",
        "    *   Remember the histogram would be of size *n_images x n_clusters*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "SR0_9HnbDFBe",
        "outputId": "ec5aa112-1dfe-4f6c-e5ed-8becc67cf7d7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.hist(kmeans.labels_, bins = 30)\n",
        "plt.suptitle('Histogram - Train Image Descriptor')\n",
        "plt.xlabel('Cluster')\n",
        "plt.ylabel('Descriptor')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmRO7dfLjgZa"
      },
      "source": [
        "\n",
        "# Creating Classification Model\n",
        "\n",
        "*   The next step is to create a classification model. We will use a C-Support Vector Classification for creating the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "K7VTBz1Oimtz"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrit95Ud6pUU"
      },
      "source": [
        "*   Use GridSearchCV to find the optimal value of C and Gamma."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "IjFFpykV-GOI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b735b635-3a69-4d8e-e522-490f9916cbea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=SVC(),\n",
              "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
              "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001]})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# Define C and Gamma\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001]} \n",
        "GS_SVC = GridSearchCV(SVC(), param_grid)\n",
        "\n",
        "# Get y data\n",
        "def get_y(x):\n",
        "  # Set y_train data\n",
        "  y = []\n",
        "  for label in x:  \n",
        "    y += [label[1]]\n",
        "  return y\n",
        "\n",
        "y_train = get_y(x_train)\n",
        "\n",
        "# Fitting the model for grid search\n",
        "GS_SVC.fit(x_train_descriptors_reshape, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqThTmO5j1-p"
      },
      "source": [
        "# Testing the Classification Model\n",
        "\n",
        "*   Extract descriptors using ORB for the test split\n",
        "*   Use the previously trained k-means to generate the histogram\n",
        "*   Use the classifier to predict the label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "x2Gzbww9e0pP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "16b46876-3b90-439a-e5ef-172516cdafe5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: ['butterfly' 'butterfly' 'butterfly' 'kangaroo' 'butterfly' 'butterfly'\n",
            " 'butterfly' 'butterfly' 'kangaroo' 'kangaroo' 'kangaroo' 'butterfly'\n",
            " 'butterfly' 'kangaroo' 'butterfly' 'kangaroo' 'kangaroo' 'kangaroo'\n",
            " 'kangaroo' 'kangaroo' 'kangaroo' 'dalmatian' 'dalmatian' 'dalmatian'\n",
            " 'dalmatian']\n"
          ]
        }
      ],
      "source": [
        "# List of descriptors\n",
        "x_test_descriptors = get_descriptors(x_test, ORB_detector)\n",
        "\n",
        "# Reshape test data\n",
        "x_test_descriptors_reshape = reshaper(x_test_descriptors)\n",
        "\n",
        "# Histogram\n",
        "kmeans = MiniBatchKMeans(n_clusters=25).fit(x_test_descriptors_reshape)\n",
        "plt.hist(kmeans.labels_, bins = 30)\n",
        "plt.suptitle('Histogram - Test Image Descriptor')\n",
        "plt.xlabel('Cluster')\n",
        "plt.ylabel('Descriptor')\n",
        "plt.show()\n",
        "\n",
        "# Prediction\n",
        "y_pred = GS_SVC.predict(x_test_descriptors_reshape)\n",
        "print('Prediction:', y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGyQUtU3lAEz"
      },
      "source": [
        "*   Calculate the accuracy score for the classification model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "PszxSB0Ek_Lt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "761b4166-e1d2-4060-f5ab-195c4e43fee7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['butterfly' 'butterfly' 'butterfly' 'kangaroo' 'butterfly' 'butterfly'\n",
            " 'butterfly' 'butterfly' 'kangaroo' 'kangaroo' 'kangaroo' 'butterfly'\n",
            " 'butterfly' 'kangaroo' 'butterfly' 'kangaroo' 'kangaroo' 'kangaroo'\n",
            " 'kangaroo' 'kangaroo' 'kangaroo' 'dalmatian' 'dalmatian' 'dalmatian'\n",
            " 'dalmatian']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.68"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# Set y_train data\n",
        "y_test = get_y(x_test)\n",
        "print(y_pred)\n",
        "# Accuracy\n",
        "GS_SVC.score(x_test_descriptors_reshape, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drlq-5AM615_"
      },
      "source": [
        "*   Generate the confusion matrix for the classification model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "NpqXVYrw61OG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50e73c19-d8c7-4a5b-cd05-857c182f8ba7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7, 2, 0],\n",
              "       [3, 6, 0],\n",
              "       [0, 3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "# Confusion Matrix\n",
        "confusion_matrix(y_test, y_pred, labels=['butterfly', 'kangaroo', 'dalmatian'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TN4rRra9yv_"
      },
      "source": [
        "*   Why do we use Clustering to create the codebook? \n",
        "*   What are the other techniques that can be used to create the codebook?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri9kU3wa3Rei"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*   Clustering is used to create a codebook, in order to compress the descriptors into a set of visual words. Without clustering, the number of features would be extremely large in the presence of several distinct images. It is more suitable to group similar descriptors into groups and uses centroids as visual words. \n",
        "\n",
        "\n",
        "*   To do the clustering there are several different unsupervised methods such as:\n",
        "\n",
        "    1. K-means++\n",
        "    2. Bisecting k-means\n",
        "    3. Fuzzy C-means\n",
        "    4. k-harmonic means\n",
        "\n",
        "    Since the clustering method doesn't know which points that are most relevant, it is also possible to add a step that sorts the words by their descriptive quality and reduces them to so-called Descriptive Visual Words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b47OqebCOXpq"
      },
      "source": [
        "# Increased Feature Dimensions\n",
        "\n",
        "*   Repeat the classification using features of 256 ORB keypoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "CiY8GERXOxbB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31108a70-24a3-4fb7-82e3-c04eaf9c1bb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.36\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8, 1, 0],\n",
              "       [8, 1, 0],\n",
              "       [5, 2, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# Creating the ORB detector\n",
        "ORB_detector = ORB(n_keypoints=256)\n",
        "\n",
        "## TRAIN\n",
        "# Get the descriptors from the train set\n",
        "x_train_descriptors = get_descriptors(x_train, ORB_detector)\n",
        "# Get the reshaped descriptors for the training set\n",
        "x_train_descriptors_reshape = reshaper(x_train_descriptors)\n",
        "\n",
        "# Train the model\n",
        "# Define C and Gamma\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001]} \n",
        "GS_SVC = GridSearchCV(SVC(), param_grid)\n",
        "# Fitting the model for grid search\n",
        "GS_SVC.fit(x_train_descriptors_reshape, y_train)\n",
        "\n",
        "## TEST\n",
        "# Get the descriptors from the test set\n",
        "x_test_descriptors = get_descriptors(x_test, ORB_detector)\n",
        "# Get the reshaped descriptors for the test set\n",
        "x_test_descriptors_reshape = reshaper(x_test_descriptors)\n",
        "\n",
        "# Prediction\n",
        "y_pred = GS_SVC.predict(x_test_descriptors_reshape)\n",
        "\n",
        "# Accuracy\n",
        "print('Accuracy: ', GS_SVC.score(x_test_descriptors_reshape, y_test))\n",
        "\n",
        "# Confusion Matrix\n",
        "confusion_matrix(y_test, y_pred, labels=['butterfly', 'kangaroo', 'dalmatian'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ucf5mIeHOzBf"
      },
      "source": [
        "*   What is the difference in classifier performance between using 64 keypoints and 256 keypoints?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJt7kpHcO5nV"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*   By increasing the number of key points, it is verified a dramatic reduction in the accuracy obtained. Quantitatively, the accuracy went from 68% to 36%, a discrepancy of 32%.\n",
        "\n",
        "    According to the confusion matrices, it is observed that a considerable majority of the images are classified as butterfly. Furthermore, no image is classified as dalmatian and only one is correctly addressed as a kangaroo. According to these values, the excess of detail represented by the descriptors does not constitute useful information for the classification algorithm. In this case, it loses, almost totally, the capacity to identify kangaroo or dalmatian."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ll0j8G-oIaHd"
      },
      "source": [
        "*   Will further adding more keypoints increase the performance of the algorithm?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka3z1sJVInS5"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "*   According to the previous analysis, the increment in the number of features does not necessarily increase or decrease the accuracy of a classification algorithm. The evolution of the accuracy depends on the number of key points considered priorly.\n",
        "\n",
        "    For example, from 10 to 64 (1st exercise) key points the accuracy increases, because for the image size considered, only 10 descriptors are not sufficient for a further algorithm successfully label the test set. So, with 64 key points, the information of the image is more detailed, which benefits the algorithm.\n",
        "    \n",
        "    On the contrary, increasing the key points from 64 to 256 decreases the accuracy. This is due to the fact that with 256 the image description is over-detailed, and a considerable amount of this information is not useful. Consequentially, it is inserted in the classification algorithm irrelevant information that is not characteristic of that label. In fact, it is just noise. Therefore, the algorithm performs worse than in the first case.\n",
        "\n",
        "    Overall, it is intended that the descriptors represent the useful information of image related to the correspondent label. For instance, if it is pretended to identify a kangaroo, it is more suitable to have descriptors related to key points of the kangaroo in the image, than of the background.\n",
        "\n",
        "    As a final note, in order to utilize more key points, a descriptive reduction step should be added to the clustering. This way, it is possible to select the most informative ones for the classification process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnN_t5Me7N5O"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "## **End of P3_2: Image Classification using Bag of Visual Words**\n",
        "Deadline for P3_2 submission in CampusVirtual is: **Thursday, the 17th of November, 2022**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}